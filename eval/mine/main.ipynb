{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import ast\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "  config_class = XLMRobertaConfig\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "\n",
    "    # load model body\n",
    "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "\n",
    "    # load and initialize weights\n",
    "    self.init_weights()\n",
    "\n",
    "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "\n",
    "    # use model body to get encoder representation\n",
    "    outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetworksNER(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, prototype_size):\n",
    "        super(PrototypicalNetworksNER, self).__init__()\n",
    "\n",
    "        # self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.prototype_size = prototype_size\n",
    "        self.encoder = encoder\n",
    "        self.fc1 = nn.Linear(hidden_size, prototype_size)\n",
    "\n",
    "\n",
    "    def build_prototypes(self, support_set, num_classes, get_prototypes=False):\n",
    "\n",
    "      prototypes = torch.zeros(num_classes, self.prototype_size).to(device)\n",
    "      all_prototypes = [[] for clas in range(num_classes)]\n",
    "      # count of each class\n",
    "      class_counts = torch.zeros(num_classes).to(device)\n",
    "      for hidden_states, labels in support_set:\n",
    "        for hidden_state, label in zip(hidden_states.squeeze(), labels):\n",
    "\n",
    "          prototype = self.fc1(hidden_state)\n",
    "          prototypes[label] += prototype.to(device)\n",
    "          class_counts[label]+=1\n",
    "\n",
    "          if get_prototypes:\n",
    "            all_prototypes[label].append(prototype)\n",
    "      # mean\n",
    "      prototypes = prototypes/class_counts.unsqueeze(1)\n",
    "      prototypes = torch.nan_to_num(prototypes, 0.)\n",
    "      if get_prototypes:\n",
    "        return prototypes, all_prototypes\n",
    "      return prototypes\n",
    "\n",
    "\n",
    "    def predict_query_set(self, query_set, prototypes):\n",
    "        distances = []\n",
    "        for hidden_states in query_set:\n",
    "          hidden_states = hidden_states.squeeze()\n",
    "          q_prototype = self.fc1(hidden_states)\n",
    "          distance = torch.cdist(q_prototype, prototypes)\n",
    "          # To get the closest prototype\n",
    "          # predicted_labels = F.softmax(distances, dim=1)\n",
    "          distances.append(distance)\n",
    "        return distances\n",
    "\n",
    "    def forward(self, support_set, query_set, num_classes, get_prototypes=False):\n",
    "        '''\n",
    "        input:\n",
    "            Tokenized Support Set\n",
    "            Tokenized Query Set\n",
    "\n",
    "        Output of encoder (Roberta Model)\n",
    "            sequence output: (1, 256, 768)\n",
    "\n",
    "        Final Outputs:\n",
    "            Distances\n",
    "        '''\n",
    "\n",
    "        hidden_support_set, hidden_query_set = [], []\n",
    "        for item in support_set:\n",
    "          s_input_ids, s_attention_mask, s_labels = item\n",
    "          s_hidden_states = self.encoder(input_ids=s_input_ids.to(device), attention_mask=s_attention_mask.to(device))['last_hidden_state']\n",
    "          hidden_support_set.append([s_hidden_states, s_labels])\n",
    "        if get_prototypes:\n",
    "          prototypes, all_protos = self.build_prototypes(hidden_support_set, num_classes, get_prototypes)\n",
    "        else:\n",
    "          prototypes = self.build_prototypes(hidden_support_set, num_classes)\n",
    "\n",
    "        q_input_ids, q_attention_mask, q_labels = query_set\n",
    "        q_hidden_states = self.encoder(input_ids=q_input_ids.to(device), attention_mask=q_attention_mask.to(device))['last_hidden_state']\n",
    "        hidden_query_set.append(q_hidden_states)\n",
    "\n",
    "        predictions = self.predict_query_set(hidden_query_set, prototypes)\n",
    "\n",
    "        del hidden_support_set\n",
    "        del hidden_query_set\n",
    "        del s_input_ids\n",
    "        del s_attention_mask\n",
    "        del s_labels\n",
    "        del s_hidden_states\n",
    "        del q_input_ids\n",
    "        del q_attention_mask\n",
    "        gc.collect()\n",
    "\n",
    "        if get_prototypes:\n",
    "          return predictions, all_protos\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "HIDDEN_SIZE = 768\n",
    "PROTOTYPE_SIZE = 256\n",
    "\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name)\n",
    "xlmr_model = (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device))\n",
    "model = PrototypicalNetworksNER(xlmr_model, HIDDEN_SIZE, PROTOTYPE_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrototypicalNetworksNER(\n",
       "  (encoder): XLMRobertaForTokenClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('10_epoch_state_dict', map_location=torch.device('mps')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_episodes = joblib.load('eval_episodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotSampler:\n",
    "    '''\n",
    "    Samples the data from csv to episodic data with query and support set in N-way K-shot\n",
    "    n_wa: numeber of classes\n",
    "    k_shot: sample for each class\n",
    "    '''\n",
    "    def __init__(self, k_shot, n_way):\n",
    "        self.k_shot = k_shot\n",
    "        self.n_way = n_way\n",
    "\n",
    "    def extract_n_way_data(self, data):\n",
    "        n_way_data = []\n",
    "        for items in data:\n",
    "            if len(set(items[1]))==self.n_way:\n",
    "                n_way_data.append(items)\n",
    "\n",
    "        return n_way_data\n",
    "\n",
    "    def sample_data(self, n_way_data, full_data, n_episodes):\n",
    "        episodes = []\n",
    "        random.seed(42)\n",
    "        for query in random.sample(n_way_data, min(n_episodes, len(n_way_data))):\n",
    "\n",
    "            query_text = query[0]\n",
    "            query_tags = query[1]\n",
    "\n",
    "            query_tag_set = set(query_tags)\n",
    "\n",
    "            final_query_set = [query_text, query_tags]\n",
    "\n",
    "            support_data = []\n",
    "            class_counts = {k: 0 for k in query_tag_set}\n",
    "\n",
    "            for items in random.sample(full_data, len(full_data)):\n",
    "                text, labels = items\n",
    "                new_labels = []\n",
    "                for i in range(len(labels)):\n",
    "                    if labels[i] not in query_tag_set:\n",
    "                        new_labels.append('O')\n",
    "                    else:\n",
    "                        new_labels.append(labels[i])\n",
    "\n",
    "\n",
    "                tag_count_greater_k = False\n",
    "                for tag in query_tag_set:\n",
    "                    if [text, new_labels] in support_data:\n",
    "                        break\n",
    "                    if len(set(new_labels))<=1:\n",
    "                        break\n",
    "                    if len(support_data) >= self.n_way*self.k_shot:\n",
    "                        break\n",
    "                    if tag in new_labels:\n",
    "                        for ent in new_labels:\n",
    "                            if class_counts[ent]>=self.k_shot and ent!='O':\n",
    "                                tag_count_greater_k = True\n",
    "                        if not tag_count_greater_k:\n",
    "                            support_data.append([text, new_labels])\n",
    "                            for ent in set(new_labels):\n",
    "                                class_counts[ent]+=1\n",
    "\n",
    "            episodes.append({\n",
    "                'query_set': final_query_set,\n",
    "                'support_set': support_data\n",
    "            })\n",
    "\n",
    "            n_way_data.remove(query)\n",
    "\n",
    "        return episodes\n",
    "\n",
    "    def generate_episodes(self, reference_data, num_episodes):\n",
    "        extracted_data = self.extract_n_way_data(reference_data)\n",
    "        episodes = self.sample_data(extracted_data, reference_data, num_episodes)\n",
    "\n",
    "        return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PETITIONER', 'PROVISION', 'DATE', 'JUDGE', 'GPE', 'WITNESS', 'ORG', 'CASE_NUMBER', 'O', 'OTHER_PERSON', 'RESPONDENT', 'PRECEDENT', 'STATUTE', 'COURT']\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "judgement = pd.read_csv('train_judgement_bio.csv')\n",
    "df = judgement.sample(frac=1, random_state=42).copy()\n",
    "df = df.rename({'BIO_tags': 'tags'}, axis=1)\n",
    "\n",
    "def convert_to_list(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(convert_to_list)\n",
    "df['tags'] = df['tags'].apply(convert_to_list)\n",
    "\n",
    "def remove_BIO(tags):\n",
    "  new_tags = []\n",
    "  for tag in tags:\n",
    "    new_tags.append(tag.replace('I-', '').replace('B-', ''))\n",
    "\n",
    "  return new_tags\n",
    "\n",
    "df['tags'] = df['tags'].apply(remove_BIO)\n",
    "\n",
    "tag_list = df['tags'].values\n",
    "labels = [label for tags in tag_list  for label in tags]\n",
    "labels = list(set(labels))\n",
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clause', '18(1', ')', ',', '(', '2', ')', 'and', '(', '3', ')', '\\n', '(', 'a', ')', '&', '(', 'b', ')', 'were', 'transposed', 'in', 'Article', '23', 'of', 'the', 'Draft', 'Constitution', 'of', 'India', '.']\n",
      "['PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'O', 'O', 'STATUTE', 'STATUTE', 'STATUTE', 'STATUTE', 'O']\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values.tolist()\n",
    "for data in dataset:\n",
    "    print(data[0])\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(support_set, q_tokens, q_tags, eval=False):\n",
    "\n",
    "  # For support\n",
    "\n",
    "  tokenized_support_set = []\n",
    "  label2idx = {}\n",
    "  idx = 0\n",
    "  for items in support_set:\n",
    "    s_tokens, s_tags = items\n",
    "    s_tokenized = xlmr_tokenizer(s_tokens, truncation=True, is_split_into_words=True)\n",
    "\n",
    "    for tag in s_tags:\n",
    "      if tag not in label2idx:\n",
    "        label2idx[tag] = idx\n",
    "        idx+=1\n",
    "\n",
    "    labels = [label2idx[tag] for tag in s_tags]\n",
    "    word_ids = s_tokenized.word_ids()\n",
    "\n",
    "    label_ids = []\n",
    "    for word_idx in word_ids:\n",
    "      if word_idx==None:\n",
    "        label_ids.append(label2idx['O'])\n",
    "      else:\n",
    "        label_ids.append(labels[word_idx])\n",
    "\n",
    "    s_tokenized['labels'] = label_ids\n",
    "\n",
    "    tokenized_support_set.append(s_tokenized)\n",
    "\n",
    "\n",
    "  # For query\n",
    "  q_tokenized_inputs = xlmr_tokenizer(q_tokens, truncation=True, is_split_into_words=True)\n",
    "\n",
    "  if not eval:\n",
    "    q_word_ids = q_tokenized_inputs.word_ids()\n",
    "    q_labels = [label2idx[tag] for tag in q_tags]\n",
    "    q_label_ids = []\n",
    "    for word_idx in q_word_ids:\n",
    "      if word_idx==None:\n",
    "        q_label_ids.append(label2idx['O'])\n",
    "      else:\n",
    "        q_label_ids.append(q_labels[word_idx])\n",
    "\n",
    "    q_tokenized_inputs['labels'] = q_label_ids\n",
    "  else:\n",
    "    q_tokenized_inputs['labels'] = []\n",
    "\n",
    "  return q_tokenized_inputs, tokenized_support_set, label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_episodes(episodes, eval=False):\n",
    "\n",
    "    tokenized_episodes = []\n",
    "     \n",
    "    for episode in episodes:\n",
    "\n",
    "        final_support_set = []\n",
    "        final_query_set = []\n",
    "        query = episode['query_set']\n",
    "        support = episode['support_set']\n",
    "\n",
    "        q_tokens, q_tags = query\n",
    "\n",
    "        tokenized_query_set, tokenized_support_set, label2idx = tokenize_and_align_labels(support, q_tokens, q_tags, eval=eval)\n",
    "\n",
    "        if len(final_query_set)<1:\n",
    "            q_ii = torch.tensor(tokenized_query_set['input_ids']).unsqueeze(0)\n",
    "            q_am = torch.tensor(tokenized_query_set['attention_mask']).unsqueeze(0)\n",
    "            q_l = torch.tensor(tokenized_query_set['labels'])\n",
    "            final_query_set.extend([q_ii, q_am, q_l])\n",
    "\n",
    "        for support_set in tokenized_support_set:\n",
    "            s_ii = torch.tensor(support_set['input_ids']).unsqueeze(0)\n",
    "            s_am = torch.tensor(support_set['attention_mask']).unsqueeze(0)\n",
    "            s_l = torch.tensor(support_set['labels'], dtype=torch.int)\n",
    "            final_support_set.append([s_ii, s_am, s_l])\n",
    "\n",
    "        tokenized_episodes.append({\n",
    "            'query_set': final_query_set,\n",
    "            'support_set': final_support_set,\n",
    "            'label2idx': label2idx\n",
    "        })\n",
    "\n",
    "    return tokenized_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sampler = FewShotSampler(1, 3)\n",
    "eval_episodes = eval_sampler.generate_episodes(deepcopy(dataset), 401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eval_episodes = tokenize_episodes(eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(eval_eps):\n",
    "  y_true = []\n",
    "  y_preds = []\n",
    "  all_i2l = []\n",
    "  model.eval()\n",
    "  for i, episode in tqdm(enumerate(eval_eps), total=len(eval_eps)):\n",
    "    query_set = episode['query_set']\n",
    "    support_set = episode['support_set']\n",
    "    num_classes = len(episode['label2idx'])\n",
    "    i2l = {i: l for l, i in episode['label2idx'].items()}\n",
    "    _, _, query_labels = query_set\n",
    "\n",
    "    # Calculate predictions\n",
    "    eval_distances = model(support_set, query_set, num_classes)[0]\n",
    "    eval_preds = torch.argmin(eval_distances, dim=1).detach().cpu().numpy()\n",
    "\n",
    "    y_true.append(query_labels.tolist())\n",
    "    y_preds.append(eval_preds.tolist())\n",
    "    all_i2l.append(i2l)\n",
    "\n",
    "    del query_set\n",
    "    del support_set\n",
    "    del query_labels\n",
    "    del num_classes\n",
    "    gc.collect()\n",
    "\n",
    "  return y_true, y_preds, all_i2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [05:42<00:00,  1.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(401, 401)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_preds, i2l = eval(tokenized_eval_episodes)\n",
    "len(y_test), len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index2label']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(i2l, 'index2label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_pred']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_test, 'y_test')\n",
    "joblib.dump(y_preds, 'y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['OTHER_PERSON', 'GPE', 'PROVISION', 'WITNESS', 'O', 'RESPONDENT', 'DATE', 'COURT', 'CASE_NUMBER', 'JUDGE', 'STATUTE', 'PETITIONER', 'ORG', 'PRECEDENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scores_per_class(y_test, y_preds, i2l, labels=labels, metrics='f1'):\n",
    "  fscores = {l: [] for l in labels}\n",
    "  pscores = {l: [] for l in labels}\n",
    "  rscores = {l: [] for l in labels}\n",
    "  for true, pred, idx2label in zip(y_test, y_preds, i2l):\n",
    "    f_scores = f1_score(true, pred, average=None)\n",
    "    p_scores = precision_score(true, pred, average=None, zero_division=0.0)\n",
    "    r_scores = recall_score(true, pred, average=None, zero_division=0.0)\n",
    "    for i in range(len(f_scores)):\n",
    "      lab = idx2label[i]\n",
    "      fscores[lab].append(f_scores[i])\n",
    "      pscores[lab].append(p_scores[i])\n",
    "      rscores[lab].append(r_scores[i])\n",
    "\n",
    "  final_scores = {l: [] for l in labels}\n",
    "  for k in fscores:\n",
    "    final_scores[k].append(np.mean(fscores[k]))\n",
    "    final_scores[k].append(np.mean(pscores[k]))\n",
    "    final_scores[k].append(np.mean(rscores[k]))\n",
    "\n",
    "  return pd.DataFrame(final_scores, index=['Average f1 scores', 'Average precision scores', 'Average recall scores'], \n",
    "                      columns=['COURT', 'JUDGE', 'WITNESS', 'STATUTE', 'PETITIONER', 'DATE', 'OTHER_PERSON', 'PRECEDENT', 'O', 'RESPONDENT', 'GPE', 'CASE_NUMBER', 'PROVISION', 'ORG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average f1 scores</th>\n",
       "      <th>Average precision scores</th>\n",
       "      <th>Average recall scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COURT</th>\n",
       "      <td>0.880783</td>\n",
       "      <td>0.892522</td>\n",
       "      <td>0.923586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUDGE</th>\n",
       "      <td>0.819643</td>\n",
       "      <td>0.802827</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WITNESS</th>\n",
       "      <td>0.746781</td>\n",
       "      <td>0.700647</td>\n",
       "      <td>0.892677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUTE</th>\n",
       "      <td>0.946223</td>\n",
       "      <td>0.936043</td>\n",
       "      <td>0.975976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETITIONER</th>\n",
       "      <td>0.562844</td>\n",
       "      <td>0.516026</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0.977870</td>\n",
       "      <td>0.974856</td>\n",
       "      <td>0.988223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_PERSON</th>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.826266</td>\n",
       "      <td>0.844412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRECEDENT</th>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.863260</td>\n",
       "      <td>0.985839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.975036</td>\n",
       "      <td>0.986303</td>\n",
       "      <td>0.968496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONDENT</th>\n",
       "      <td>0.599435</td>\n",
       "      <td>0.550476</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>0.776251</td>\n",
       "      <td>0.764989</td>\n",
       "      <td>0.889484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <td>0.864148</td>\n",
       "      <td>0.871930</td>\n",
       "      <td>0.868224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROVISION</th>\n",
       "      <td>0.964015</td>\n",
       "      <td>0.951222</td>\n",
       "      <td>0.992255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.796729</td>\n",
       "      <td>0.870946</td>\n",
       "      <td>0.805320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average f1 scores  Average precision scores  \\\n",
       "COURT                  0.880783                  0.892522   \n",
       "JUDGE                  0.819643                  0.802827   \n",
       "WITNESS                0.746781                  0.700647   \n",
       "STATUTE                0.946223                  0.936043   \n",
       "PETITIONER             0.562844                  0.516026   \n",
       "DATE                   0.977870                  0.974856   \n",
       "OTHER_PERSON           0.813244                  0.826266   \n",
       "PRECEDENT              0.909851                  0.863260   \n",
       "O                      0.975036                  0.986303   \n",
       "RESPONDENT             0.599435                  0.550476   \n",
       "GPE                    0.776251                  0.764989   \n",
       "CASE_NUMBER            0.864148                  0.871930   \n",
       "PROVISION              0.964015                  0.951222   \n",
       "ORG                    0.796729                  0.870946   \n",
       "\n",
       "              Average recall scores  \n",
       "COURT                      0.923586  \n",
       "JUDGE                      0.859375  \n",
       "WITNESS                    0.892677  \n",
       "STATUTE                    0.975976  \n",
       "PETITIONER                 0.714286  \n",
       "DATE                       0.988223  \n",
       "OTHER_PERSON               0.844412  \n",
       "PRECEDENT                  0.985839  \n",
       "O                          0.968496  \n",
       "RESPONDENT                 0.700000  \n",
       "GPE                        0.889484  \n",
       "CASE_NUMBER                0.868224  \n",
       "PROVISION                  0.992255  \n",
       "ORG                        0.805320  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = find_scores_per_class(y_test, y_preds, i2l, metrics='f1').T\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    " \n",
    "exel = pd.ExcelWriter('outputs.xlsx')\n",
    "all_scores.to_excel(exel)\n",
    " \n",
    "exel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1573310464, 4379525120)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.current_allocated_memory(), torch.mps.driver_allocated_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
