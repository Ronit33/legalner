{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import ast\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = joblib.load('predictions')\n",
    "y_true = joblib.load('truths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, t in zip(y_preds, y_true):\n",
    "    if len(p)!=len(t):\n",
    "        print(\"Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['OTHER_PERSON', 'GPE', 'PROVISION', 'WITNESS', 'O', 'RESPONDENT', 'DATE', 'COURT', 'CASE_NUMBER', 'JUDGE', 'STATUTE', 'PETITIONER', 'ORG', 'PRECEDENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5281818181818182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true[0], y_preds[0], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8       , 1.        , 0.84090909, 0.        , 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true[0], y_preds[0], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_lookups(true):\n",
    "    all_l2i = []\n",
    "    all_i2l = []\n",
    "    for labels in true:\n",
    "        l2i = {}\n",
    "        i2l = {}\n",
    "        for i, label in enumerate(set(labels)):\n",
    "            l2i[label] = i\n",
    "            i2l[i] = label\n",
    "        all_l2i.append(l2i)\n",
    "        all_i2l.append(i2l)\n",
    "    \n",
    "    return all_l2i, all_i2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label2index, all_index2label = create_label_lookups(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'CASE_NUMBER', 1: 'O', 2: 'PRECEDENT', 3: 'DATE', 4: 'OTHER_PERSON'},\n",
       " {'CASE_NUMBER': 0, 'O': 1, 'PRECEDENT': 2, 'DATE': 3, 'OTHER_PERSON': 4})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_index2label[0], all_label2index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = []\n",
    "preds = []\n",
    "for true, pred, l2i in zip(y_true, y_preds, all_label2index):\n",
    "    p = []\n",
    "    t = []\n",
    "    for i in range(len(true)):\n",
    "        t.append(l2i[true[i]])\n",
    "        p.append(l2i[pred[i]] if pred[i] in l2i else l2i['O'])\n",
    "    trues.append(t)\n",
    "    preds.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scores_per_class(y_test, y_preds, i2l, labels=labels, metrics='f1'):\n",
    "  fscores = {l: [] for l in labels}\n",
    "  pscores = {l: [] for l in labels}\n",
    "  rscores = {l: [] for l in labels}\n",
    "  for true, pred, idx2label in zip(y_test, y_preds, i2l):\n",
    "    f_scores = f1_score(true, pred, average=None)\n",
    "    p_scores = precision_score(true, pred, average=None, zero_division=0.0)\n",
    "    r_scores = recall_score(true, pred, average=None, zero_division=0.0)\n",
    "    for i in range(len(f_scores)):\n",
    "      lab = idx2label[i]\n",
    "      fscores[lab].append(f_scores[i])\n",
    "      pscores[lab].append(p_scores[i])\n",
    "      rscores[lab].append(r_scores[i])\n",
    "\n",
    "  final_scores = {l: [] for l in labels}\n",
    "  for k in fscores:\n",
    "    final_scores[k].append(np.mean(fscores[k]))\n",
    "    final_scores[k].append(np.mean(pscores[k]))\n",
    "    final_scores[k].append(np.mean(rscores[k]))\n",
    "\n",
    "  return pd.DataFrame(final_scores, index=['Average f1 scores', 'Average precision scores', 'Average recall scores'], \n",
    "                      columns=['COURT', 'JUDGE', 'WITNESS', 'STATUTE', 'PETITIONER', 'DATE', 'OTHER_PERSON', 'PRECEDENT', 'O', 'RESPONDENT', 'GPE', 'CASE_NUMBER', 'PROVISION', 'ORG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average f1 scores</th>\n",
       "      <th>Average precision scores</th>\n",
       "      <th>Average recall scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COURT</th>\n",
       "      <td>0.675770</td>\n",
       "      <td>0.664222</td>\n",
       "      <td>0.741199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUDGE</th>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.380936</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WITNESS</th>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.095546</td>\n",
       "      <td>0.178295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUTE</th>\n",
       "      <td>0.431894</td>\n",
       "      <td>0.414364</td>\n",
       "      <td>0.570165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETITIONER</th>\n",
       "      <td>0.326299</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.395982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0.812099</td>\n",
       "      <td>0.825970</td>\n",
       "      <td>0.844376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_PERSON</th>\n",
       "      <td>0.377405</td>\n",
       "      <td>0.347924</td>\n",
       "      <td>0.475284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRECEDENT</th>\n",
       "      <td>0.239919</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.229718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.847897</td>\n",
       "      <td>0.821153</td>\n",
       "      <td>0.898467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONDENT</th>\n",
       "      <td>0.445926</td>\n",
       "      <td>0.427302</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>0.214632</td>\n",
       "      <td>0.235099</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <td>0.528065</td>\n",
       "      <td>0.595093</td>\n",
       "      <td>0.554420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROVISION</th>\n",
       "      <td>0.277686</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>0.319305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.428678</td>\n",
       "      <td>0.457249</td>\n",
       "      <td>0.457074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average f1 scores  Average precision scores  \\\n",
       "COURT                  0.675770                  0.664222   \n",
       "JUDGE                  0.417722                  0.380936   \n",
       "WITNESS                0.112838                  0.095546   \n",
       "STATUTE                0.431894                  0.414364   \n",
       "PETITIONER             0.326299                  0.321429   \n",
       "DATE                   0.812099                  0.825970   \n",
       "OTHER_PERSON           0.377405                  0.347924   \n",
       "PRECEDENT              0.239919                  0.284459   \n",
       "O                      0.847897                  0.821153   \n",
       "RESPONDENT             0.445926                  0.427302   \n",
       "GPE                    0.214632                  0.235099   \n",
       "CASE_NUMBER            0.528065                  0.595093   \n",
       "PROVISION              0.277686                  0.300365   \n",
       "ORG                    0.428678                  0.457249   \n",
       "\n",
       "              Average recall scores  \n",
       "COURT                      0.741199  \n",
       "JUDGE                      0.518519  \n",
       "WITNESS                    0.178295  \n",
       "STATUTE                    0.570165  \n",
       "PETITIONER                 0.395982  \n",
       "DATE                       0.844376  \n",
       "OTHER_PERSON               0.475284  \n",
       "PRECEDENT                  0.229718  \n",
       "O                          0.898467  \n",
       "RESPONDENT                 0.520000  \n",
       "GPE                        0.225000  \n",
       "CASE_NUMBER                0.554420  \n",
       "PROVISION                  0.319305  \n",
       "ORG                        0.457074  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = find_scores_per_class(trues, preds, all_index2label).T\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    " \n",
    "exel = pd.ExcelWriter('outputs.xlsx')\n",
    "all_scores.to_excel(exel)\n",
    " \n",
    "exel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
