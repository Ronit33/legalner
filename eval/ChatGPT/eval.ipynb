{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import ast\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = joblib.load('y_preds')\n",
    "y_true = joblib.load('y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, t in zip(y_preds, y_true):\n",
    "    if len(p)!=len(t):\n",
    "        print(\"Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['OTHER_PERSON', 'GPE', 'PROVISION', 'WITNESS', 'O', 'RESPONDENT', 'DATE', 'COURT', 'CASE_NUMBER', 'JUDGE', 'STATUTE', 'PETITIONER', 'ORG', 'PRECEDENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6481720430107527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true[0], y_preds[0], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8       , 1.        , 0.77419355, 0.        , 0.66666667])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true[0], y_preds[0], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_lookups(true):\n",
    "    all_l2i = []\n",
    "    all_i2l = []\n",
    "    for labels in true:\n",
    "        l2i = {}\n",
    "        i2l = {}\n",
    "        for i, label in enumerate(set(labels)):\n",
    "            l2i[label] = i\n",
    "            i2l[i] = label\n",
    "        all_l2i.append(l2i)\n",
    "        all_i2l.append(i2l)\n",
    "    \n",
    "    return all_l2i, all_i2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label2index, all_index2label = create_label_lookups(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O', 1: 'OTHER_PERSON', 2: 'PRECEDENT', 3: 'CASE_NUMBER', 4: 'DATE'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_index2label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATE': 0, 'O': 1, 'OTHER_PERSON': 2, 'PRECEDENT': 3, 'CASE_NUMBER': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_label2index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = []\n",
    "preds = []\n",
    "for true, pred, l2i in zip(y_true, y_preds, all_label2index):\n",
    "    p = []\n",
    "    t = []\n",
    "    for i in range(len(true)):\n",
    "        t.append(l2i[true[i]])\n",
    "        p.append(l2i[pred[i]] if pred[i] in l2i else l2i['O'])\n",
    "    trues.append(t)\n",
    "    preds.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scores_per_class(y_test, y_preds, i2l, labels=labels, metrics='f1'):\n",
    "  all_scores = {l: [] for l in labels}\n",
    "  for true, pred, idx2label in zip(y_test, y_preds, i2l):\n",
    "    if metrics=='f1':\n",
    "      scores = f1_score(true, pred, average=None)\n",
    "    if metrics=='precision':\n",
    "      scores = precision_score(true, pred, average=None, zero_division=0.0)\n",
    "    elif metrics=='recall':\n",
    "      scores = recall_score(true, pred, average=None, zero_division=0.0)\n",
    "    for i in range(len(scores)):\n",
    "      lab = idx2label[i]\n",
    "      all_scores[lab].append(scores[i])\n",
    "\n",
    "  final_scores = {l: [] for l in labels}\n",
    "  for k, v in all_scores.items():\n",
    "    final_scores[k] = np.mean(v)\n",
    "\n",
    "  return pd.DataFrame(final_scores, index=[f'Average {metrics} scores'], \n",
    "                      columns=['COURT', 'JUDGE', 'WITNESS', 'STATUTE', 'PETITIONER', 'DATE', 'OTHER_PERSON', 'PRECEDENT', 'O', 'RESPONDENT', 'GPE', 'CASE_NUMBER', 'PROVISION', 'ORG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average precision scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COURT</th>\n",
       "      <td>0.427042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUDGE</th>\n",
       "      <td>0.589311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WITNESS</th>\n",
       "      <td>0.358063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUTE</th>\n",
       "      <td>0.208337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETITIONER</th>\n",
       "      <td>0.360788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0.670182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_PERSON</th>\n",
       "      <td>0.209916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRECEDENT</th>\n",
       "      <td>0.361695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.839365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONDENT</th>\n",
       "      <td>0.362381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>0.235149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <td>0.468992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROVISION</th>\n",
       "      <td>0.461076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.361934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average precision scores\n",
       "COURT                         0.427042\n",
       "JUDGE                         0.589311\n",
       "WITNESS                       0.358063\n",
       "STATUTE                       0.208337\n",
       "PETITIONER                    0.360788\n",
       "DATE                          0.670182\n",
       "OTHER_PERSON                  0.209916\n",
       "PRECEDENT                     0.361695\n",
       "O                             0.839365\n",
       "RESPONDENT                    0.362381\n",
       "GPE                           0.235149\n",
       "CASE_NUMBER                   0.468992\n",
       "PROVISION                     0.461076\n",
       "ORG                           0.361934"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores = find_scores_per_class(trues, preds, all_index2label, metrics='precision').T\n",
    "precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average f1 scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COURT</th>\n",
       "      <td>0.450952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUDGE</th>\n",
       "      <td>0.644912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WITNESS</th>\n",
       "      <td>0.448511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUTE</th>\n",
       "      <td>0.207847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETITIONER</th>\n",
       "      <td>0.387229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0.662891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_PERSON</th>\n",
       "      <td>0.225324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRECEDENT</th>\n",
       "      <td>0.361472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.848185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONDENT</th>\n",
       "      <td>0.402479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>0.234996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROVISION</th>\n",
       "      <td>0.460828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.367604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average f1 scores\n",
       "COURT                  0.450952\n",
       "JUDGE                  0.644912\n",
       "WITNESS                0.448511\n",
       "STATUTE                0.207847\n",
       "PETITIONER             0.387229\n",
       "DATE                   0.662891\n",
       "OTHER_PERSON           0.225324\n",
       "PRECEDENT              0.361472\n",
       "O                      0.848185\n",
       "RESPONDENT             0.402479\n",
       "GPE                    0.234996\n",
       "CASE_NUMBER            0.452315\n",
       "PROVISION              0.460828\n",
       "ORG                    0.367604"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = find_scores_per_class(trues, preds, all_index2label).T\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average recall scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COURT</th>\n",
       "      <td>0.526055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUDGE</th>\n",
       "      <td>0.809091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WITNESS</th>\n",
       "      <td>0.725775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUTE</th>\n",
       "      <td>0.237758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETITIONER</th>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>0.688949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_PERSON</th>\n",
       "      <td>0.282037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRECEDENT</th>\n",
       "      <td>0.411625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.885816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONDENT</th>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>0.276389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <td>0.518390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROVISION</th>\n",
       "      <td>0.642675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.439690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average recall scores\n",
       "COURT                      0.526055\n",
       "JUDGE                      0.809091\n",
       "WITNESS                    0.725775\n",
       "STATUTE                    0.237758\n",
       "PETITIONER                 0.484848\n",
       "DATE                       0.688949\n",
       "OTHER_PERSON               0.282037\n",
       "PRECEDENT                  0.411625\n",
       "O                          0.885816\n",
       "RESPONDENT                 0.533333\n",
       "GPE                        0.276389\n",
       "CASE_NUMBER                0.518390\n",
       "PROVISION                  0.642675\n",
       "ORG                        0.439690"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scores = find_scores_per_class(trues, preds, all_index2label, metrics='recall').T\n",
    "recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    " \n",
    "exel = pd.ExcelWriter('recall.xlsx')\n",
    "recall_scores.to_excel(exel)\n",
    " \n",
    "exel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_f1_score = []\n",
    "final_acc = []\n",
    "for y_true, y_pred in zip(trues, preds):\n",
    "    final_f1_score.append(f1_score(y_true, y_pred, average='macro'))\n",
    "    final_acc.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "final_f1_score = np.mean(final_f1_score)\n",
    "final_acc = np.mean(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4886614331846166, 0.7594979546308163)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_f1_score, final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
