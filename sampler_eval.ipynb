{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>BIO_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['\\n\\n', '(', '7', ')', 'On', 'specific', 'que...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['He', 'was', 'also', 'asked', 'whether', 'Agy...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'B-OTHER_PERSON', 'O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[' \\n', '5.2', 'CW3', 'Mr', 'Vijay', 'Mishra',...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B-WITNESS', 'I-WITNESS',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['You', 'are', 'hereby', 'asked', 'not', 'to',...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['The', 'pillion', 'rider', 'T.V.', 'Satyanara...</td>\n",
       "      <td>['O', 'O', 'O', 'B-OTHER_PERSON', 'I-OTHER_PER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  ['\\n\\n', '(', '7', ')', 'On', 'specific', 'que...   \n",
       "1  ['He', 'was', 'also', 'asked', 'whether', 'Agy...   \n",
       "2  [' \\n', '5.2', 'CW3', 'Mr', 'Vijay', 'Mishra',...   \n",
       "3  ['You', 'are', 'hereby', 'asked', 'not', 'to',...   \n",
       "4  ['The', 'pillion', 'rider', 'T.V.', 'Satyanara...   \n",
       "\n",
       "                                            BIO_tags  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'B-OTHER_PERSON', 'O...  \n",
       "2  ['O', 'O', 'O', 'O', 'B-WITNESS', 'I-WITNESS',...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4  ['O', 'O', 'O', 'B-OTHER_PERSON', 'I-OTHER_PER...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement = pd.read_csv('train_judgement_bio.csv')\n",
    "judgement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>['Clause', '18(1', ')', ',', '(', '2', ')', 'a...</td>\n",
       "      <td>['B-PROVISION', 'I-PROVISION', 'I-PROVISION', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>['The', 'order', 'can', 'not', 'be', 'said', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>['Ajit', 'Kumar', 'Guha', '(', 'D.', 'W.', '1'...</td>\n",
       "      <td>['B-WITNESS', 'I-WITNESS', 'I-WITNESS', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>['The', 'purpose', 'of', 'entering', 'into', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>['It', 'is', 'admitted', 'that', 'the', 'vehic...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "4613  ['Clause', '18(1', ')', ',', '(', '2', ')', 'a...   \n",
       "1103  ['The', 'order', 'can', 'not', 'be', 'said', '...   \n",
       "5214  ['Ajit', 'Kumar', 'Guha', '(', 'D.', 'W.', '1'...   \n",
       "3315  ['The', 'purpose', 'of', 'entering', 'into', '...   \n",
       "5363  ['It', 'is', 'admitted', 'that', 'the', 'vehic...   \n",
       "\n",
       "                                                   tags  \n",
       "4613  ['B-PROVISION', 'I-PROVISION', 'I-PROVISION', ...  \n",
       "1103  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "5214  ['B-WITNESS', 'I-WITNESS', 'I-WITNESS', 'O', '...  \n",
       "3315  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "5363  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = judgement.sample(frac=1, random_state=42).copy()\n",
    "df = df.rename({'BIO_tags': 'tags'}, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>[Clause, 18(1, ), ,, (, 2, ), and, (, 3, ), \\n...</td>\n",
       "      <td>[B-PROVISION, I-PROVISION, I-PROVISION, I-PROV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>[The, order, can, not, be, said, to, be, wrong...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>[Ajit, Kumar, Guha, (, D., W., 1, ), ,, who, w...</td>\n",
       "      <td>[B-WITNESS, I-WITNESS, I-WITNESS, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>[The, purpose, of, entering, into, a, contract...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>[It, is, admitted, that, the, vehicle, bearing...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "4613  [Clause, 18(1, ), ,, (, 2, ), and, (, 3, ), \\n...   \n",
       "1103  [The, order, can, not, be, said, to, be, wrong...   \n",
       "5214  [Ajit, Kumar, Guha, (, D., W., 1, ), ,, who, w...   \n",
       "3315  [The, purpose, of, entering, into, a, contract...   \n",
       "5363  [It, is, admitted, that, the, vehicle, bearing...   \n",
       "\n",
       "                                                   tags  \n",
       "4613  [B-PROVISION, I-PROVISION, I-PROVISION, I-PROV...  \n",
       "1103  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5214  [B-WITNESS, I-WITNESS, I-WITNESS, O, O, O, O, ...  \n",
       "3315  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5363  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_list(s):\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(convert_to_list)\n",
    "df['tags'] = df['tags'].apply(convert_to_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4613    [PROVISION, PROVISION, PROVISION, PROVISION, P...\n",
       "1103    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "5214    [WITNESS, WITNESS, WITNESS, O, O, O, O, O, O, ...\n",
       "3315    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "5363    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_BIO(tags):\n",
    "  new_tags = []\n",
    "  for tag in tags:\n",
    "    new_tags.append(tag.replace('I-', '').replace('B-', ''))\n",
    "\n",
    "  return new_tags\n",
    "\n",
    "df['tags'] = df['tags'].apply(remove_BIO)\n",
    "df['tags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OTHER_PERSON', 'GPE', 'PROVISION', 'WITNESS', 'O', 'RESPONDENT', 'DATE', 'COURT', 'CASE_NUMBER', 'JUDGE', 'STATUTE', 'PETITIONER', 'ORG', 'PRECEDENT']\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "tag_list = df['tags'].values\n",
    "labels = [label for tags in tag_list  for label in tags]\n",
    "labels = list(set(labels))\n",
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Even, if, the, decision, of, the, Bombay, Hig...</td>\n",
       "      <td>[O, O, O, O, O, O, COURT, COURT, COURT, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Under, the, aforesaid, deed, ,, which, has, c...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, DATE, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We, have, a, Judgment, of, learned, Single, J...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, JUDGE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[By, further, order, dated, November, 1, ,, 19...</td>\n",
       "      <td>[O, O, O, O, DATE, DATE, DATE, DATE, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Time, must, have, been, taken, by, both, PW14...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, WITNESS, WITNESS, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[The, present, case, has, been, instituted, on...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, PETITIONE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[Various, complaints, were, filed, against, th...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[Application, of, Section, 29, of, the, Contra...</td>\n",
       "      <td>[O, O, PROVISION, PROVISION, O, O, STATUTE, ST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>[(, ALOK, VERMA, ), Judge, manju, M.Cr, ., C.N...</td>\n",
       "      <td>[O, JUDGE, JUDGE, O, O, O, CASE_NUMBER, CASE_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>[Mr., Kapadia, has, relied, upon, the, decisio...</td>\n",
       "      <td>[O, OTHER_PERSON, O, O, O, O, O, O, O, COURT, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens  \\\n",
       "0    [Even, if, the, decision, of, the, Bombay, Hig...   \n",
       "1    [Under, the, aforesaid, deed, ,, which, has, c...   \n",
       "2    [We, have, a, Judgment, of, learned, Single, J...   \n",
       "3    [By, further, order, dated, November, 1, ,, 19...   \n",
       "4    [Time, must, have, been, taken, by, both, PW14...   \n",
       "..                                                 ...   \n",
       "396  [The, present, case, has, been, instituted, on...   \n",
       "397  [Various, complaints, were, filed, against, th...   \n",
       "398  [Application, of, Section, 29, of, the, Contra...   \n",
       "399  [(, ALOK, VERMA, ), Judge, manju, M.Cr, ., C.N...   \n",
       "400  [Mr., Kapadia, has, relied, upon, the, decisio...   \n",
       "\n",
       "                                                  tags  \n",
       "0    [O, O, O, O, O, O, COURT, COURT, COURT, O, O, ...  \n",
       "1    [O, O, O, O, O, O, O, O, O, O, O, DATE, O, O, ...  \n",
       "2    [O, O, O, O, O, O, O, O, O, O, O, O, O, JUDGE,...  \n",
       "3    [O, O, O, O, DATE, DATE, DATE, DATE, O, O, O, ...  \n",
       "4    [O, O, O, O, O, O, O, O, WITNESS, WITNESS, O, ...  \n",
       "..                                                 ...  \n",
       "396  [O, O, O, O, O, O, O, O, O, O, O, O, PETITIONE...  \n",
       "397  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, PRO...  \n",
       "398  [O, O, PROVISION, PROVISION, O, O, STATUTE, ST...  \n",
       "399  [O, JUDGE, JUDGE, O, O, O, CASE_NUMBER, CASE_N...  \n",
       "400  [O, OTHER_PERSON, O, O, O, O, O, O, O, COURT, ...  \n",
       "\n",
       "[401 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_5_way = df[df['tags'].apply(lambda x: len(set(x))==5)].sample(frac=1, random_state=42).reset_index().drop(columns='index', axis=1).copy()\n",
    "data_5_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clause', '18(1', ')', ',', '(', '2', ')', 'and', '(', '3', ')', '\\n', '(', 'a', ')', '&', '(', 'b', ')', 'were', 'transposed', 'in', 'Article', '23', 'of', 'the', 'Draft', 'Constitution', 'of', 'India', '.']\n",
      "['PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'O', 'O', 'STATUTE', 'STATUTE', 'STATUTE', 'STATUTE', 'O']\n"
     ]
    }
   ],
   "source": [
    "dataset = deepcopy(df.values.tolist())\n",
    "for data in dataset:\n",
    "    print(data[0])\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotSampler:\n",
    "    '''\n",
    "    Samples the data from csv to episodic data with query and support set in N-way K-shot\n",
    "    n_wa: numeber of classes\n",
    "    k_shot: sample for each class\n",
    "    '''\n",
    "    def __init__(self, n_way):\n",
    "        self.n_way = n_way\n",
    "\n",
    "    def extract_n_way_data(self, data):\n",
    "        n_way_data = []\n",
    "        for items in data:\n",
    "            if len(set(items[1]))==self.n_way:\n",
    "                n_way_data.append(items)\n",
    "        \n",
    "        return n_way_data\n",
    "    \n",
    "    def sample_data(self, n_way_data, full_data, n_episodes):\n",
    "        episodes = []\n",
    "        random.seed(42)\n",
    "        for query in random.sample(n_way_data, min(n_episodes, len(n_way_data))):\n",
    "\n",
    "            query_text = query[0]\n",
    "            query_tags = query[1]\n",
    "\n",
    "            query_tag_set = set(query_tags)\n",
    "\n",
    "            final_query_set = [query_text, query_tags]\n",
    "\n",
    "            support_data = []\n",
    "            class_counts = {k: 0 for k in query_tag_set}\n",
    "            \n",
    "            for items in random.sample(full_data, len(full_data)):\n",
    "                if len(support_data)>=8:\n",
    "                        break\n",
    "                text, labels = items\n",
    "                new_labels = []\n",
    "                for i in range(len(labels)):\n",
    "                    if labels[i] not in query_tag_set:\n",
    "                        new_labels.append('O')\n",
    "                    else:\n",
    "                        new_labels.append(labels[i])\n",
    "                \n",
    "\n",
    "                for tag in query_tag_set:\n",
    "                    if len(support_data)>=8:\n",
    "                        break\n",
    "                    if [text, new_labels] in support_data or ''.join(text) == ''.join(query_text):\n",
    "                        break\n",
    "                    if len(set(new_labels))<2:\n",
    "                        break\n",
    "                    if tag in new_labels and class_counts[tag]<2:\n",
    "                        support_data.append([text, new_labels])\n",
    "                        for ent in set(new_labels):\n",
    "                                class_counts[ent]+=1\n",
    "\n",
    "\n",
    "            \n",
    "            if len(support_data)<8:\n",
    "                for items in random.sample(full_data, 8):\n",
    "                    if len(support_data)>=8:\n",
    "                        break\n",
    "                    text, labels = items\n",
    "                    new_labels = []\n",
    "                    for i in range(len(labels)):\n",
    "                        if labels[i] not in query_tag_set:\n",
    "                            new_labels.append('O')\n",
    "                        else:\n",
    "                            new_labels.append(labels[i])\n",
    "                    \n",
    "                    if [text, new_labels] in support_data or ''.join(text) == ''.join(query_text):\n",
    "                        break\n",
    "\n",
    "                    support_data.append([text, new_labels])    \n",
    "\n",
    "\n",
    "            episodes.append({\n",
    "                'query_set': final_query_set,\n",
    "                'support_set': support_data\n",
    "            })\n",
    "            \n",
    "            n_way_data.remove(query)\n",
    "        \n",
    "        return episodes\n",
    "\n",
    "    def generate_episodes(self, reference_data, num_episodes):\n",
    "        extracted_data = self.extract_n_way_data(reference_data)\n",
    "        episodes = self.sample_data(extracted_data, reference_data, num_episodes)\n",
    "\n",
    "        return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = FewShotSampler(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = sampler.generate_episodes(deepcopy(dataset), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_episode(episodes, idx):\n",
    "    print('Query set')\n",
    "    print(episodes[idx]['query_set'][0])\n",
    "    print(episodes[idx]['query_set'][1])\n",
    "    print(set(episodes[idx]['query_set'][1]))\n",
    "    print('-'*300)\n",
    "    print('-'*300)\n",
    "    print('Support Set')\n",
    "    for support in episodes[idx]['support_set']:\n",
    "        text, support_entity = support\n",
    "        print(f\"Text - {text}\")\n",
    "        print(f\"Labels - {support_entity}\")\n",
    "        print('SET: ')\n",
    "        print(set(support_entity))\n",
    "        print('-'*300)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, episode in enumerate(episodes):\n",
    "    if len(episode['support_set'])!=8:\n",
    "        print('Not equal to 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, episode in enumerate(episodes):\n",
    "    query_set_tags = set(episode['query_set'][1])\n",
    "    support_set_tags = set()\n",
    "    for s_item in episode['support_set']:\n",
    "        s_tags = s_item[1]\n",
    "        support_set_tags.update(s_tags)\n",
    "    \n",
    "    if sorted(query_set_tags) != sorted(support_set_tags):\n",
    "        print('Found tags in query set that do not belong in support set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query set\n",
      "['Earlier', 'the', 'accused', 'was', 'convicted', 'vide', 'judgment', 'dated', '23rd', 'August', ',', '1999', 'delivered', 'in', 'Sessions', 'Trial', 'No.325/1994', 'by', 'Sessions', 'Judge', 'Morena', 'for', 'commission', 'of', 'the', 'offence', 'under', 'section', '302', 'IPC', 'and', 'awarded', 'life', 'imprisonment', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATE', 'DATE', 'DATE', 'DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'JUDGE', 'O', 'O', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'STATUTE', 'O', 'O', 'O', 'O', 'O']\n",
      "{'PROVISION', 'DATE', 'O', 'JUDGE', 'STATUTE'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Support Set\n",
      "Text - ['That', 'is', 'why', 'this', 'item', 'will', 'also', 'be', 'governed', 'by', 'Appendix', '10', 'as', 'an', 'O.G.L.', 'item', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'O', 'O', 'O', 'O', 'O']\n",
      "SET: \n",
      "{'O', 'PROVISION'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['The', 'next', 'contention', 'of', 'the', 'learned', 'Government', 'Advo', 'ste', ',', 'end', 'an', 'important', 'one', ',', 'is', 'that', 'the', 'three', 'contracts', 'are', 'void', 'and', 'unenforceable', 'against', 'the', 'Government', 'as', 'they', 'have', 'not', 'been', 'executed', 'in', 'accordance', 'with', 'the', 'provisions', 'of', 'Sub', '-', 'section', '(', '3', ')', 'of', 'Section', '175', 'of', 'the', 'Government', 'of', 'India', 'Act', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'O', 'O', 'STATUTE', 'STATUTE', 'STATUTE', 'STATUTE', 'O']\n",
      "SET: \n",
      "{'O', 'STATUTE', 'PROVISION'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['We', 'may', ',', 'with', 'advantage', ',', 'consider', 'at', 'this', 'juncture', ',', 'the', 'essential', 'distinction', 'between', 'an', ':', 'order', 'passed', 'under', 'Section', '145(6', ')', 'and', 'one', 'passed', 'under', 'Section', '146', 'of', 'the', 'Code', 'of', 'Criminal', 'Procedure', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'PROVISION', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'O', 'O', 'STATUTE', 'STATUTE', 'STATUTE', 'STATUTE', 'O']\n",
      "SET: \n",
      "{'O', 'STATUTE', 'PROVISION'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['The', 'petitioner', 'filed', 'a', 'representation', 'before', 'the', 'State', 'of', 'U.P.', 'through', 'Secretary', 'Home', 'Secretary', ',', 'State', 'of', 'U.P.', 'and', 'before', 'the', 'Union', 'of', 'India', 'through', 'Home', 'Secretary', 'and', 'also', 'before', 'the', 'District', 'Magistrate', ',', 'Banda', 'on', '12.08.2014', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATE', 'O']\n",
      "SET: \n",
      "{'DATE', 'O'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['On', '19', '-', '4', '-', '1991', 'the', 'learned', 'Magistrate', 'forwarded', 'the', 'said', 'complaint', 'to', 'the', 'Station', 'House', 'Officer', ',', 'II', 'Town', 'Police', 'Station', ',', 'Kakinada', 'under', 'S.', '156(3', ')', 'of', 'the', 'Cr', '.', 'P.C.', 'for', 'investigation', '.']\n",
      "Labels - ['O', 'DATE', 'DATE', 'DATE', 'DATE', 'DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'PROVISION', 'O', 'O', 'STATUTE', 'STATUTE', 'STATUTE', 'O', 'O', 'O']\n",
      "SET: \n",
      "{'DATE', 'O', 'STATUTE', 'PROVISION'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['Learned', 'counsel', 'for', 'the', 'plaintiff', 'has', 'submitted', 'that', 'compromise', 'was', 'arrived', 'at', 'between', 'the', 'parties', 'before', 'Ms.', 'R.', 'Kiran', 'Nath', ',', 'the', 'then', 'learned', 'Additional', 'District', 'Judge', ',', 'Dwarka', ',', 'New', 'Delhi', ',', 'and', 'vide', 'Order', '/', 'decree', 'dated', '03.07.2010', ',', 'the', 'suit', 'was', 'disposed', 'of', 'as', 'settled', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'JUDGE', 'JUDGE', 'JUDGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "SET: \n",
      "{'DATE', 'O', 'JUDGE'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['^', '\\n     ', 'HELD', ':', '(', 'per', 'Krishna', 'Iyer', '&', 'Chinnappa', 'Reddy', ',', 'JJ', '.', ')', '\\n     ', '1', '.', 'Reservation', ' ', 'of', '70', '%', 'is', 'too', 'high', 'at', 'the', 'post', '-', 'graduate', 'level', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'JUDGE', 'JUDGE', 'O', 'JUDGE', 'JUDGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "SET: \n",
      "{'O', 'JUDGE'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Text - ['Basing', 'on', 'the', 'complaint', 'of', 'the', 'petitioner', ',', 'the', 'Station', 'House', 'Officer', ',', 'Atchampet', 'Police', 'Station', ',', 'Mahabubnagar', 'District', 'registered', 'a', 'case', 'in', 'Crime', 'No.30', 'of', '2007', 'for', 'the', 'offences', 'under', 'Section', '498A', ',', '506', 'and', '509', 'IPC', 'against', 'the', 'first', 'respondent', '.']\n",
      "Labels - ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'PROVISION', 'STATUTE', 'O', 'O', 'O', 'O', 'O']\n",
      "SET: \n",
      "{'O', 'STATUTE', 'PROVISION'}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_episode(episodes, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(support_set, q_tokens, q_tags, eval=False):\n",
    "\n",
    "  # For support\n",
    "\n",
    "  tokenized_support_set = []\n",
    "  label2idx = {}\n",
    "  idx = 0\n",
    "  for items in support_set:\n",
    "    s_tokens, s_tags = items\n",
    "    s_tokenized = xlmr_tokenizer(s_tokens, truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    for tag in s_tags:\n",
    "      if tag not in label2idx:\n",
    "        label2idx[tag] = idx\n",
    "        idx+=1\n",
    "\n",
    "    labels = [label2idx[tag] for tag in s_tags]\n",
    "    word_ids = s_tokenized.word_ids()\n",
    "\n",
    "    label_ids = []\n",
    "    for word_idx in word_ids:\n",
    "      if word_idx==None:\n",
    "        label_ids.append(label2idx['O'])\n",
    "      else:\n",
    "        label_ids.append(labels[word_idx])\n",
    "\n",
    "    s_tokenized['labels'] = label_ids\n",
    "\n",
    "    tokenized_support_set.append(s_tokenized)\n",
    "\n",
    "\n",
    "  # For query\n",
    "  q_tokenized_inputs = xlmr_tokenizer(q_tokens, truncation=True, is_split_into_words=True)\n",
    "\n",
    "  if not eval:\n",
    "    q_word_ids = q_tokenized_inputs.word_ids()\n",
    "    q_labels = [label2idx[tag] for tag in q_tags]\n",
    "    q_label_ids = []\n",
    "    for word_idx in q_word_ids:\n",
    "      if word_idx==None:\n",
    "        q_label_ids.append(label2idx['O'])\n",
    "      else:\n",
    "        q_label_ids.append(q_labels[word_idx])\n",
    "\n",
    "    q_tokenized_inputs['labels'] = q_label_ids\n",
    "  else:\n",
    "    q_tokenized_inputs['labels'] = []\n",
    "\n",
    "  return q_tokenized_inputs, tokenized_support_set, len(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_episodes(episodes):\n",
    "    \n",
    "    tokenized_episodes = []\n",
    "        \n",
    "    for episode in episodes:\n",
    "\n",
    "        final_support_set = []\n",
    "        final_query_set = []\n",
    "        query = episode['query_set']\n",
    "        support = episode['support_set']\n",
    "\n",
    "        q_tokens, q_tags = query\n",
    "\n",
    "        tokenized_query_set, tokenized_support_set, num_classes = tokenize_and_align_labels(support, q_tokens, q_tags)\n",
    "\n",
    "        if len(final_query_set)<1:\n",
    "            q_ii = torch.tensor(tokenized_query_set['input_ids']).unsqueeze(0)\n",
    "            q_am = torch.tensor(tokenized_query_set['attention_mask']).unsqueeze(0)\n",
    "            q_l = torch.tensor(tokenized_query_set['labels'])\n",
    "            final_query_set.extend([q_ii, q_am, q_l])\n",
    "\n",
    "        for support_set in tokenized_support_set:\n",
    "            s_ii = torch.tensor(support_set['input_ids']).unsqueeze(0)\n",
    "            s_am = torch.tensor(support_set['attention_mask']).unsqueeze(0)\n",
    "            s_l = torch.tensor(support_set['labels'], dtype=torch.int)\n",
    "            final_support_set.append([s_ii, s_am, s_l])\n",
    "\n",
    "        tokenized_episodes.append({\n",
    "            'query_set': final_query_set,\n",
    "            'support_set': final_support_set,\n",
    "            'num_classes': num_classes\n",
    "        })\n",
    "    \n",
    "    return tokenized_episodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_episodes = tokenize_episodes(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,   5443,      6,      5,    436,      5,   4235,     83,    563,\n",
      "          30508,  13416,      6,      4,   7440,     73,     70, 181595,  31068,\n",
      "          13483,   1919,  31330,    607,    297,    953,  28705,  34498, 113771,\n",
      "            450,     98, 165045,  42276,   3378,   1363,      6,      4,     70,\n",
      "         121413,  70541,    297,     23,     70,  43824,    126,  94419,    335,\n",
      "          26038,  24491, 109921,    100,     70, 169424,    111, 185256, 209716,\n",
      "              7,    111,   5798, 173857,    297, 130090,    111,    233,   6664,\n",
      "          19441,    615,   5039,   1745,     15,   1632,   6275,    300,     86,\n",
      "          45234,  33297,   1388,      6, 178851,   1212,      6,      5,      2]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for episode in tokenized_episodes:\n",
    "    query_set = episode['query_set'] \n",
    "    support_set = episode['support_set']\n",
    "    num_classes = episode['num_classes']\n",
    "    q_ii, q_am, q_l = query_set\n",
    "    for item in support_set:\n",
    "        s_ii, s_am, s_l = item\n",
    "        print(s_ii)\n",
    "        print(s_am)\n",
    "        print(s_l)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_episodes[0]['support_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
